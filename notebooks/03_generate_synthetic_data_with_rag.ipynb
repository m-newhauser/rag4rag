{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rag4rag: Using RAG to generate data for model fine-tuning\n",
    "\n",
    "In this notebook, we accomplish the following:\n",
    "* Load our dataset of synthetically-generated answers and their hallucinated spans and confidence scores\n",
    "* Choose a confidence score threshold for classifying an answer as a hallucination\n",
    "* Subset the dataset to include only hallucinations\n",
    "* Use a vanilla RAG pipeline (LangChain + FAISS) to generate new answers\n",
    "* Run the new RAG answers through LettuceDetect to check for hallucinations\n",
    "* Compare the new RAG answers with the previous answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "from datasets import Dataset, load_dataset\n",
    "from lettucedetect.models.inference import HallucinationDetector\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import logging\n",
    "\n",
    "# Suppress warnings (as you did)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Suppress all logging below ERROR level for the root logger\n",
    "logging.getLogger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['context', 'anchor', 'human_positive', 'synthetic_positive', 'synthetic_negative', 'hallucinated_span', 'confidence'],\n",
       "        num_rows: 4989\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load synthetic RAG dataset with detected hallucination\n",
    "ds = load_dataset(\"m-newhauser/rag-synthetic-distilabel-hallucinations\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>anchor</th>\n",
       "      <th>human_positive</th>\n",
       "      <th>synthetic_positive</th>\n",
       "      <th>synthetic_negative</th>\n",
       "      <th>hallucinated_span</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "      <td>The Virgin Mary allegedly appeared to Bernadet...</td>\n",
       "      <td>The Virgin Mary appeared in the sky as the sun...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>a copper statue of Christ</td>\n",
       "      <td>In front of the Notre Dame Main Building, you'...</td>\n",
       "      <td>The main building's roof is painted in bright ...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>the Main Building</td>\n",
       "      <td>The Basilica of the Sacred Heart at Notre Dame...</td>\n",
       "      <td>The basilica's heart-shaped design was inspire...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>a Marian place of prayer and reflection</td>\n",
       "      <td>The Grotto at Notre Dame is a sacred replica o...</td>\n",
       "      <td>The grotto was filled with colorful lights and...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>a golden statue of the Virgin Mary</td>\n",
       "      <td>The iconic Golden Dome sits on top of the Main...</td>\n",
       "      <td>The main course sits on top of the dining tabl...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  Architecturally, the school has a Catholic cha...   \n",
       "1  Architecturally, the school has a Catholic cha...   \n",
       "2  Architecturally, the school has a Catholic cha...   \n",
       "3  Architecturally, the school has a Catholic cha...   \n",
       "4  Architecturally, the school has a Catholic cha...   \n",
       "\n",
       "                                              anchor  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...   \n",
       "1  What is in front of the Notre Dame Main Building?   \n",
       "2  The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                  What is the Grotto at Notre Dame?   \n",
       "4  What sits on top of the Main Building at Notre...   \n",
       "\n",
       "                            human_positive  \\\n",
       "0               Saint Bernadette Soubirous   \n",
       "1                a copper statue of Christ   \n",
       "2                        the Main Building   \n",
       "3  a Marian place of prayer and reflection   \n",
       "4       a golden statue of the Virgin Mary   \n",
       "\n",
       "                                  synthetic_positive  \\\n",
       "0  The Virgin Mary allegedly appeared to Bernadet...   \n",
       "1  In front of the Notre Dame Main Building, you'...   \n",
       "2  The Basilica of the Sacred Heart at Notre Dame...   \n",
       "3  The Grotto at Notre Dame is a sacred replica o...   \n",
       "4  The iconic Golden Dome sits on top of the Main...   \n",
       "\n",
       "                                  synthetic_negative hallucinated_span  \\\n",
       "0  The Virgin Mary appeared in the sky as the sun...                     \n",
       "1  The main building's roof is painted in bright ...                     \n",
       "2  The basilica's heart-shaped design was inspire...                     \n",
       "3  The grotto was filled with colorful lights and...                     \n",
       "4  The main course sits on top of the dining tabl...                     \n",
       "\n",
       "   confidence  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform dataset to dataframe\n",
    "df = ds[\"train\"].to_pandas()\n",
    "\n",
    "# Preview the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually set threshold\n",
    "threshold = 0.9\n",
    "\n",
    "# Filter the DataFrame for hallucinations based on the threshold\n",
    "hallucinations_df = (\n",
    "    df\n",
    "    .query(\"confidence != ''\")\n",
    "    .query(f\"confidence >= {threshold}\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI API key variable name\n",
    "openai_api_key_var = \"OPENAI_API_KEY\"  # Replace with the name of your secret/env var\n",
    "\n",
    "# Fetch API key from environment variable\n",
    "import os\n",
    "openai_api_key = os.getenv(openai_api_key_var)\n",
    "if not openai_api_key:\n",
    "    raise EnvironmentError(\n",
    "        f\"Environment variable '{openai_api_key_var}' is not set. \"\n",
    "        \"Please define it before running this script.\"\n",
    "    )\n",
    "\n",
    "openai.api_key = openai_api_key_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Langchain RAG pipeline first constructs a [FAISS](https://github.com/facebookresearch/faiss) vector store from provided text contexts by embedding them with OpenAI's embeddings. Then, it uses Langchain's RetrievalQA chain, configured with an OpenAI LLM and a retriever based on the vector store, to generate answers for a list of input questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "contexts = hallucinations_df[\"context\"].tolist()\n",
    "anchors = hallucinations_df[\"anchor\"].tolist()\n",
    "human_positives = hallucinations_df[\"human_positive\"].tolist()\n",
    "\n",
    "# Create a vectorstore from the *unique* contexts\n",
    "unique_contexts = hallucinations_df[\"context\"].unique().tolist()\n",
    "docs = [Document(page_content=ctx) for ctx in unique_contexts]\n",
    "embedding = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_documents(docs, embedding)\n",
    "\n",
    "prompt_template = \"\"\"You are an expert information extraction system.\n",
    "Your task is to answer the question using ONLY the information provided in the following context.\n",
    "The answer to the question is GUARANTEED to be found DIRECTLY within the context.\n",
    "You MUST provide the exact answer as it appears in the context, without adding any extra words or explanations.\n",
    "Your answer must be as concise as possible and not a full sentence.\n",
    "Do not say things like \"According to the context,\" or rephrase the answer.\n",
    "If the question asks for a specific piece of information (e.g., a year, a name), provide ONLY that specific piece of information.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "CUSTOM_PROMPT = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "# Create a retriever + QA chain\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 1})\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=OpenAI(), \n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": CUSTOM_PROMPT},\n",
    ")\n",
    "\n",
    "# Run the RAG pipeline for each anchor and strip newlines\n",
    "rag_answers = []\n",
    "for anchor in anchors:\n",
    "    answer = qa.run(anchor)\n",
    "    cleaned_answer = answer.replace('\\n', ' ').strip()  # Replace newlines with spaces and trim\n",
    "    rag_answers.append(cleaned_answer)\n",
    "\n",
    "# Put the answers into a dataframe, aligning by index\n",
    "df = pd.DataFrame({\n",
    "    \"context\": contexts,\n",
    "    \"question\": anchors,\n",
    "    \"human_positive\": human_positives,\n",
    "    \"rag_positive\": rag_answers,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the hallucination detector model\n",
    "detector = HallucinationDetector(\n",
    "    method=\"transformer\", model_path=\"KRLabsOrg/lettucedect-base-modernbert-en-v1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run over the RAG dataset\n",
    "def predict_hallucinations(row):\n",
    "    predictions = detector.predict(\n",
    "        context=[row['context']],\n",
    "        question=row['question'],\n",
    "        answer=row['rag_positive'],\n",
    "        output_format=\"spans\"\n",
    "    )\n",
    "    # Assuming predictions is a list of dictionaries\n",
    "    if predictions:\n",
    "        return predictions[0].get('text', ''), predictions[0].get('confidence', 0.0)\n",
    "    return '', ''\n",
    "\n",
    "# Apply the function to each row of the DataFrame\n",
    "df[['hallucinated_span', 'confidence']] = df.apply(predict_hallucinations, axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace blank strings with NaN\n",
    "df['confidence'] = df['confidence'].replace('', pd.NA)\n",
    "\n",
    "# Convert the column to numeric (float or int)\n",
    "df['confidence'] = pd.to_numeric(df['confidence'], errors='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Dataset\n",
    "ds = Dataset.from_pandas(df)\n",
    "\n",
    "# Save to Hub\n",
    "ds.push_to_hub(\"m-newhauser/rag4rag-synthetic-hallucinations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset hallucinations based on the threshold\n",
    "threshold = 0.9\n",
    "hallucinations_df = df.query(\"confidence != ''\").query(f\"confidence >= {threshold}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print stats regarding hallucinations\n",
    "print(f\"Total hallucinations detected: {hallucinations_df.shape[0]} ({hallucinations_df.shape[0]/df.shape[0] * 100:.2f}%)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_data",
   "language": "python",
   "name": "rag_data"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
